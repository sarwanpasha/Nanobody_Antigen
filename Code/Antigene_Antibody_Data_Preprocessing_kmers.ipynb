{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d62af9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packages imported\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import random\n",
    "# import seaborn as sns\n",
    "import os.path as path\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.font_manager\n",
    "import matplotlib.pyplot as plt # graphs plotting\n",
    "# from Bio import SeqIO # some BioPython that will come in handy\n",
    "#matplotlib inline\n",
    "import numpy\n",
    "import csv \n",
    "\n",
    "from matplotlib import rc\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "from sklearn.neural_network import MLPClassifier \n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from pandas import DataFrame\n",
    "\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from numpy import mean\n",
    "from Bio.SeqUtils.ProtParam import ProteinAnalysis\n",
    "\n",
    "\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import statistics\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import itertools\n",
    "from itertools import product\n",
    "\n",
    "import timeit\n",
    "\n",
    "import math\n",
    "\n",
    "# for Arial typefont\n",
    "matplotlib.rcParams['font.family'] = 'Arial'\n",
    "\n",
    "\n",
    "## for Palatino and other serif fonts use:\n",
    "# rc('font',**{'family':'serif','serif':['Palatino']})\n",
    "# matplotlib.rcParams['mathtext.fontset'] = 'cm'\n",
    "\n",
    "## for LaTeX typefont\n",
    "# matplotlib.rcParams['mathtext.fontset'] = 'stix'\n",
    "# matplotlib.rcParams['font.family'] = 'STIXGeneral'\n",
    "\n",
    "## for another LaTeX typefont\n",
    "# rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "\n",
    "# rc('text', usetex = True)\n",
    "\n",
    "print(\"Packages imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505f2902",
   "metadata": {},
   "source": [
    "# Reading Antigene Nanobody Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a64ce4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read the Excel file\n",
    "excel_file_path = 'E:/RA/Antigene_Antibody/Dataset/New/Ag-Nb Binding Data with Sequences - Sheet1.csv'\n",
    "\n",
    "\n",
    "data = []\n",
    "counter = 0\n",
    "# Open the CSV file in text mode\n",
    "with open(excel_file_path, 'r') as file:\n",
    "    # Create a CSV reader\n",
    "    csv_reader = csv.reader(file)\n",
    "    \n",
    "    # Loop over each row in the CSV file\n",
    "    for row in csv_reader:\n",
    "        if counter>0:\n",
    "            aa = str(row).split(\",\")\n",
    "            aa[0] = aa[0].replace(\"[\",\"\").replace(\"\\'\",\"\").replace(\" \",\"\").replace(\"]\",\"\")\n",
    "            aa[1] = aa[1].replace(\"[\",\"\").replace(\"\\'\",\"\").replace(\" \",\"\").replace(\"]\",\"\")\n",
    "            aa[2] = aa[2].replace(\"[\",\"\").replace(\"\\'\",\"\").replace(\" \",\"\").replace(\"]\",\"\")\n",
    "            aa[3] = aa[3].replace(\"[\",\"\").replace(\"\\'\",\"\").replace(\" \",\"\").replace(\"]\",\"\")\n",
    "            aa[4] = aa[4].replace(\"[\",\"\").replace(\"\\'\",\"\").replace(\" \",\"\").replace(\"]\",\"\")\n",
    "            aa[5] = aa[5].replace(\"[\",\"\").replace(\"\\'\",\"\").replace(\" \",\"\").replace(\"]\",\"\")\n",
    "            aa[6] = aa[6].replace(\"[\",\"\").replace(\"\\'\",\"\").replace(\" \",\"\").replace(\"]\",\"\")\n",
    "            aa[7] = aa[7].replace(\"[\",\"\").replace(\"\\'\",\"\").replace(\" \",\"\").replace(\"]\",\"\")\n",
    "            aa[8] = aa[8].replace(\"[\",\"\").replace(\"\\'\",\"\").replace(\" \",\"\").replace(\"]\",\"\")\n",
    "            data.append(aa)\n",
    "        counter = counter + 1\n",
    "#         print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e35ee12d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['sdAb_6274_Sy',\n",
       "  'NB_1_AG_1',\n",
       "  'NTV4',\n",
       "  'SyntheticConstruct',\n",
       "  'AG_1',\n",
       "  'Vascularendothelialgrowthfactor(VEGF)receptorVEGFR-2domain3(VEGFRD3)',\n",
       "  'MAQVQLLESGGGLVQPGGSLRLSCAASGVTITDEDMTRVRQAPGKGLEWVSSILNTGGSTYYADSVKGRFTISRDNSKNTLYLQMNSLRAEDTAVYYCAAVHEKAADMNFWGQGTLVTVSS',\n",
       "  'DHNPFISVEWLKGPILEATAGDELVKLPVKLAAYPPPEFQWYKDGKALSGRHSPHALVLKEVTEASTGTYTLALWNSAAGLRRNISLELVVNVPPQIHEKEASSPSIYSRHSRQALTCTAYGVPLPLSIQWHWRPWTPCKMFAQRSLRRRQQQDLMPQCRDWRAVTTQDAVNPIESLDTWTEFVEGKNKTVSKLVIQNANVSAMYKCVVSNKVGQDERLIYFYVTTHHHHHH',\n",
       "  '4BSJ_1'],\n",
       " 365)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data[0]),len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6631a87d",
   "metadata": {},
   "source": [
    "# Reading Alignment Distance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "b012af38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read the Excel file\n",
    "excel_file_path = 'E:/RA/Antigene_Antibody/Dataset/New/Antibodies_Pairwise_Distance_Matrix.csv'\n",
    "\n",
    "\n",
    "distance_matrix = []\n",
    "header_name = []\n",
    "\n",
    "counter = 0\n",
    "# Open the CSV file in text mode\n",
    "with open(excel_file_path, 'r') as file:\n",
    "    # Create a CSV reader\n",
    "    csv_reader = csv.reader(file)\n",
    "    \n",
    "    # Loop over each row in the CSV file\n",
    "    for row in csv_reader:\n",
    "        if counter>0:\n",
    "            aa = str(row).split(\",\")\n",
    "            aa_arr = []\n",
    "            for j in range(1,len(aa)):\n",
    "                aa_arr.append(float(aa[j].replace(\" \",\"\").replace(\"\\'\",\"\").replace(\"]\",\"\")))\n",
    "            distance_matrix.append(aa_arr)\n",
    "            header_name.append(aa[0].replace(\"[\",\"\").replace(\"]\",\"\").replace(\"\\'\",\"\").replace(\" \",\"\"))\n",
    "        counter = counter + 1\n",
    "#         print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "ec9f0c57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['AG_1',\n",
       "  'AG_2',\n",
       "  'AG_3',\n",
       "  'AG_39',\n",
       "  'AG_4',\n",
       "  'AG_5',\n",
       "  'AG_6',\n",
       "  'AG_7',\n",
       "  'AG_8',\n",
       "  'AG_10'],\n",
       " 47)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_name[0:10],len(header_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "47d121e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nanobody_sequences = []\n",
    "antigene_sequences = []\n",
    "binding_label = []\n",
    "nanobody_name = []\n",
    "antigen_name = []\n",
    "antigene_id_org = []\n",
    "\n",
    "for i in range(len(data)):\n",
    "    temp = data[i]\n",
    "    nanobody_sequences.append(temp[6])\n",
    "    antigene_sequences.append(temp[7])\n",
    "    binding_label.append(\"Yes\")\n",
    "    nanobody_name.append(temp[2])\n",
    "    antigen_name.append(temp[5])\n",
    "    antigene_id_org.append(temp[4])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "587ad97c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(365, 'AG_1')"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nanobody_sequences),antigene_id_org[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63434c4e",
   "metadata": {},
   "source": [
    "# Getting all possible NOT binding information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "312cc54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nanobody_sequences_NO = []\n",
    "antigene_sequences_NO = []\n",
    "binding_label_NO = []\n",
    "nanobody_name_NO = []\n",
    "antigen_name_NO = []\n",
    "antigene_id_NO = []\n",
    "antigene_id_YES = []\n",
    "\n",
    "\n",
    "for i in range(len(nanobody_sequences)):\n",
    "    name_NB = nanobody_name[i]\n",
    "    name_AG = antigen_name[i]\n",
    "    nb_seq = nanobody_sequences[i]\n",
    "    antigene_id_test = antigene_id_org[i]\n",
    "    for j in range(len(nanobody_sequences)):\n",
    "        name_AG_new = antigen_name[j]\n",
    "        if name_AG==name_AG_new:\n",
    "            a=1\n",
    "        else:\n",
    "            nanobody_sequences_NO.append(nb_seq)\n",
    "            antigene_sequences_NO.append(antigene_sequences[j])\n",
    "            binding_label_NO.append(\"No\")\n",
    "            nanobody_name_NO.append(nanobody_name[j])\n",
    "            antigen_name_NO.append(antigen_name[j])\n",
    "            antigene_id_NO.append(antigene_id_org[j])\n",
    "            antigene_id_YES.append(antigene_id_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "74eeae53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# antigene_id_YES[0:10],antigene_id_NO[0:10],len(antigene_id_NO)\n",
    "\n",
    "distance_values = []\n",
    "\n",
    "for i in range(len(nanobody_sequences_NO)):\n",
    "# for i in range(0,10):\n",
    "    row_id = antigene_id_YES[i]\n",
    "    row_val = (np.where(np.array(header_name) == row_id))[0][0]\n",
    "    \n",
    "    col_id = antigene_id_NO[i]\n",
    "    col_val = (np.where(np.array(header_name) == col_id))[0][0]\n",
    "    \n",
    "#     print(row_val,\",\",col_val)\n",
    "    \n",
    "    distance_values.append(np.array(distance_matrix)[row_val,col_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "69ad7a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('AG_8', 'AG_47', 0.89, 126490, 126490)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_val = 10000\n",
    "antigene_id_YES[id_val],antigene_id_NO[id_val],distance_values[id_val],len(distance_values),len(nanobody_sequences_NO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93914aec",
   "metadata": {},
   "source": [
    "# Filter based on distance values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "ce57f068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108050, 126490)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_No_nanobody_sequences = []\n",
    "filtered_No_antigene_sequences = []\n",
    "filtered_No_distance_values = []\n",
    "filtered_No_label_value = []\n",
    "\n",
    "No_distance_value_threshold = 0.85\n",
    "\n",
    "for i in range(len(distance_values)):\n",
    "    if distance_values[i] >= No_distance_value_threshold:\n",
    "        filtered_No_nanobody_sequences.append(nanobody_sequences_NO[i])\n",
    "        filtered_No_antigene_sequences.append(antigene_sequences_NO[i])\n",
    "        filtered_No_distance_values.append(distance_values[i])\n",
    "        filtered_No_label_value.append(\"No\")\n",
    "\n",
    "len(filtered_No_nanobody_sequences),len(nanobody_sequences_NO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "33d67246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1388, 126490)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_Yes_nanobody_sequences = []\n",
    "filtered_Yes_antigene_sequences = []\n",
    "filtered_Yes_distance_values = []\n",
    "filtered_Yes_label_value = []\n",
    "\n",
    "Yes_distance_value_threshold = 0.20\n",
    "\n",
    "for i in range(len(distance_values)):\n",
    "    if distance_values[i] <= Yes_distance_value_threshold:\n",
    "        filtered_Yes_nanobody_sequences.append(nanobody_sequences_NO[i])\n",
    "        filtered_Yes_antigene_sequences.append(antigene_sequences_NO[i])\n",
    "        filtered_Yes_distance_values.append(distance_values[i])\n",
    "        filtered_Yes_label_value.append(\"Yes\")\n",
    "\n",
    "len(filtered_Yes_nanobody_sequences),len(nanobody_sequences_NO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "5f4dfdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# antigene_first_index = (np.where(np.array(antigene_id_org) == 'AG_1'))\n",
    "# antigene_second_index = np.where(np.array(antigene_id_NO) == 'AG_2')\n",
    "\n",
    "# # Find the intersecting values between the two arrays\n",
    "# intersect_values = np.intersect1d(np.array(antigene_first_index), np.array(antigene_second_index))\n",
    "\n",
    "# antigene_first_index[0][intersect_values],antigene_second_index[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "4e061b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# antigene_id_org[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0538b940",
   "metadata": {},
   "source": [
    "# Getting Random Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "b781d759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1728, 108050)"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the random seed for reproducibility\n",
    "np.random.seed(123)\n",
    "\n",
    "# Calculate the number of rows to select (20% of the total rows)\n",
    "rows_percentage_selected = 1.6\n",
    "num_rows = int((rows_percentage_selected/100) * len(filtered_No_nanobody_sequences))\n",
    "# Select random rows\n",
    "nanobody_sequences_NO_random_rows = np.random.choice(filtered_No_nanobody_sequences, size=num_rows, replace=False)\n",
    "antigene_sequences_NO_random_rows = np.random.choice(filtered_No_antigene_sequences, size=num_rows, replace=False)\n",
    "binding_label_NO_random_rows = np.random.choice(filtered_No_label_value, size=num_rows, replace=False)\n",
    "\n",
    "len(nanobody_sequences_NO_random_rows),len(filtered_No_nanobody_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "25c720d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DVQLVESGGGLVQPGGSLRLSCAASGFTFSSYYMSWARQAPGKGPEWVSTINTGGGRMGYADSVKGRFTISRDNTKNTLYLHMNSLKPEDTALYYCARGDYDDSLRRRYWGQGTQVTVSS'"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nanobody_sequences_NO_random_rows[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e4bc2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ea36b4c",
   "metadata": {},
   "source": [
    "# Merging Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "0109f9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(365, 1728, 1388, 3481)"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nanobody_sequences_full = nanobody_sequences[:]\n",
    "antigene_sequences_full = antigene_sequences[:]\n",
    "labels_full = binding_label[:]\n",
    "\n",
    "for i in range(len(nanobody_sequences_NO_random_rows)):\n",
    "    nanobody_sequences_full.append(nanobody_sequences_NO_random_rows[i])\n",
    "    antigene_sequences_full.append(antigene_sequences_NO_random_rows[i])\n",
    "    labels_full.append(binding_label_NO_random_rows[i])\n",
    "    \n",
    "    \n",
    "# filtered_Yes_nanobody_sequences.append(nanobody_sequences_NO[i])\n",
    "# filtered_Yes_antigene_sequences.append(antigene_sequences_NO[i])\n",
    "# filtered_Yes_distance_values.append(distance_values[i])\n",
    "# filtered_Yes_label_value.append(\"Yes\")\n",
    "        \n",
    "for i in range(len(filtered_Yes_nanobody_sequences)):\n",
    "    nanobody_sequences_full.append(filtered_Yes_nanobody_sequences[i])\n",
    "    antigene_sequences_full.append(filtered_Yes_antigene_sequences[i])\n",
    "    labels_full.append(filtered_Yes_label_value[i])\n",
    "\n",
    "\n",
    "len(nanobody_sequences),len(nanobody_sequences_NO_random_rows),len(filtered_Yes_nanobody_sequences),len(nanobody_sequences_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "25fec82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are all of the viral species in the dataset: \n",
      " 3481 entries in total\n",
      "Yes    1753\n",
      "No     1728\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "idx = pd.Index(labels_full) # creates an index which allows counting the entries easily\n",
    "print('Here are all of the viral species in the dataset: \\n', len(idx),\"entries in total\")\n",
    "aq = idx.value_counts()\n",
    "print(aq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "f32fdb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3481\n",
      "Attribute data preprocessing Done\n"
     ]
    }
   ],
   "source": [
    "unique_hst = list(np.unique(labels_full))\n",
    "\n",
    "int_hosts = []\n",
    "for ind_unique in range(len(labels_full)):\n",
    "    variant_tmp = labels_full[ind_unique]\n",
    "    ind_tmp = unique_hst.index(variant_tmp)\n",
    "    int_hosts.append(ind_tmp)\n",
    "    \n",
    "print(len(int_hosts))\n",
    "print(\"Attribute data preprocessing Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fc0ae3",
   "metadata": {},
   "source": [
    "# Get other properties of the protein sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "d3ae743d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = ProteinAnalysis(\"MAEGEITTFTALTEKFNLPPGNYKKPKLLYCSNGGHFLRILPDGTVDGT\"\n",
    "#                     \"RDRSDQHIQLQLSAESVGEVYIKSTETGQYLAMDTSGLLYGSQTPSEEC\"\n",
    "#                     \"LFLERLEENHYNTYTSKKHAEKFVGKNGSCKRGPRTHYGQKAILF\"\n",
    "#                     \"LP\")\n",
    "\n",
    "nanobody_sequences_feat = []\n",
    "for i in range(len(nanobody_sequences_full)):\n",
    "#     X = nanobody_sequences_full[i]\n",
    "    X = ProteinAnalysis(nanobody_sequences_full[i].replace(\"O\",\"A\").replace(\"B\",\"A\").replace(\"X\",\"A\"))\n",
    "    epsilon_prot = X.molar_extinction_coefficient()  # [reduced, oxidized]\n",
    "    sec_struc = X.secondary_structure_fraction()  # [helix, turn, sheet]\n",
    "    gravy_val = X.gravy()\n",
    "    # protein_scale_val = X.protein_scale(param_dict, window, edge=1.0)\n",
    "    # flexibility_val = X.flexibility()\n",
    "    charge_at_pH_val = X.charge_at_pH(1)\n",
    "    all_features = [charge_at_pH_val,gravy_val,X.molecular_weight(),X.aromaticity(),X.instability_index(),X.isoelectric_point(),sec_struc[0],sec_struc[1],sec_struc[2],epsilon_prot[0],epsilon_prot[1]]\n",
    "    # for ii in range(len(flexibility_val)):\n",
    "    #     all_features.append(flexibility_val[ii])\n",
    "    # all_features,charge_at_pH_val\n",
    "    nanobody_sequences_feat.append(np.array(all_features))\n",
    "\n",
    "\n",
    "antigene_sequences_feat = []\n",
    "for i in range(len(antigene_sequences_full)):\n",
    "#     X = antigene_sequences_full[i]\n",
    "    X = ProteinAnalysis(antigene_sequences_full[i].replace(\"O\",\"A\").replace(\"B\",\"A\").replace(\"X\",\"A\"))\n",
    "    epsilon_prot = X.molar_extinction_coefficient()  # [reduced, oxidized]\n",
    "    sec_struc = X.secondary_structure_fraction()  # [helix, turn, sheet]\n",
    "    gravy_val = X.gravy()\n",
    "    charge_at_pH_val = X.charge_at_pH(1)\n",
    "    all_features = [charge_at_pH_val,gravy_val,X.molecular_weight(),X.aromaticity(),X.instability_index(),X.isoelectric_point(),sec_struc[0],sec_struc[1],sec_struc[2],epsilon_prot[0],epsilon_prot[1]]\n",
    "    antigene_sequences_feat.append(np.array(all_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "133dbb4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3481"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_data_1 = nanobody_sequences_full[:]\n",
    "seq_data_2 = antigene_sequences_full[:]\n",
    "\n",
    "len(seq_data_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea50fef",
   "metadata": {},
   "source": [
    "# Generating k-mers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "fe43e90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq_data\n",
    "# attr_new\n",
    "def build_kmers(sequence, ksize):\n",
    "    # https://homolog.us/blogs/bioinfo/2017/10/25/intro-minimizer/\n",
    "#     seq=\"ATGCGATATCGTAGGCGTCGATGGAGAGCTAGATCGATCGATCTAAATCCCGATCGATTCCGAGCGCGATCAAAGCGCGATAGGCTAGCTAAAGCTAGCA\"\n",
    "#     sequence = seq[:]\n",
    "\n",
    "#     asd = str(sequence)\n",
    "#     asd = np.array2string(sequence)\n",
    "    \n",
    "    string_parsing = []\n",
    "    for ind_test in range(len(sequence)):\n",
    "        string_parsing.append(str(sequence[ind_test]))\n",
    "    \n",
    "    asd = str(string_parsing)\n",
    "    aa_lst_1 = asd.replace(\",\",\"\")\n",
    "    aa_lst_2 = aa_lst_1.replace(\"[\",\"\")\n",
    "    aa_lst_3 = aa_lst_2.replace(\"\\\"\",\"\")\n",
    "    aa_lst_4 = aa_lst_3.replace(\"]\",\"\")\n",
    "    aa_lst_5 = aa_lst_4.replace(\"'\",\"\")\n",
    "    aa_lst_6 = aa_lst_5.replace(\" \",\"\")\n",
    "    aa_lst_6\n",
    "\n",
    "#     print(aa_lst_6)\n",
    "    seq = aa_lst_6[:]\n",
    "#     rev=seq[::-1]\n",
    "    \n",
    "    Kmer=ksize\n",
    "#     M=m_size\n",
    "    L=len(seq)\n",
    "\n",
    "#     minimizers = []\n",
    "    k_mers_final = []\n",
    "    for i in range(0, L-Kmer+1):\n",
    "\n",
    "            sub_f=seq[i:i+Kmer]\n",
    "            k_mers_final.append(sub_f)\n",
    "#             print(sub_f,min)\n",
    "\n",
    "#     print(\"unique minimizers = \",len(np.unique(minimizers)))\n",
    "#     print(\"unique kmers = \",len(np.unique(k_mers_final)))\n",
    "\n",
    "    return k_mers_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "47e991d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmers Time :  71.55117719999907\n"
     ]
    }
   ],
   "source": [
    "seq_data = seq_data_1[:]\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "\n",
    "k_size_val = 3\n",
    "\n",
    "kmers_freq_vec = []\n",
    "for protein_kmers in range(len(seq_data)):\n",
    "    temp = seq_data[protein_kmers]\n",
    "    k_mers_vals = build_kmers(temp,k_size_val) \n",
    "    kmers_freq_vec.append(k_mers_vals)\n",
    "    \n",
    "unique_seq_kmers_final_list = [''.join(c) for c in product('ABCDEFGHIJKLMNOPQRSTUVWXYZ', repeat=3)]  \n",
    "\n",
    "frequency_vector = []\n",
    "#cnt_check2 = 0\n",
    "for ii in range(len(kmers_freq_vec)):\n",
    "    seq_tmp = kmers_freq_vec[ii]\n",
    "    listofzeros = [0] * len(unique_seq_kmers_final_list)\n",
    "    for j in range(len(seq_tmp)):\n",
    "        ind_tmp = unique_seq_kmers_final_list.index(seq_tmp[j])\n",
    "        listofzeros[ind_tmp] = listofzeros[ind_tmp] + 1\n",
    "    frequency_vector.append(listofzeros)\n",
    "    \n",
    "stop = timeit.default_timer()\n",
    "print(\"kmers Time : \", stop - start) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "63f827b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmers Time :  447.52487649999966\n"
     ]
    }
   ],
   "source": [
    "seq_data = seq_data_2[:]\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "\n",
    "k_size_val = 3\n",
    "\n",
    "kmers_freq_vec_1 = []\n",
    "for protein_kmers in range(len(seq_data)):\n",
    "    temp = seq_data[protein_kmers]\n",
    "    k_mers_vals = build_kmers(temp,k_size_val) \n",
    "    kmers_freq_vec_1.append(k_mers_vals)\n",
    "    \n",
    "unique_seq_kmers_final_list = [''.join(c) for c in product('ABCDEFGHIJKLMNOPQRSTUVWXYZ', repeat=3)]  \n",
    "\n",
    "frequency_vector_1 = []\n",
    "#cnt_check2 = 0\n",
    "for ii in range(len(kmers_freq_vec_1)):\n",
    "    seq_tmp = kmers_freq_vec_1[ii]\n",
    "    listofzeros = [0] * len(unique_seq_kmers_final_list)\n",
    "    for j in range(len(seq_tmp)):\n",
    "        ind_tmp = unique_seq_kmers_final_list.index(seq_tmp[j])\n",
    "        listofzeros[ind_tmp] = listofzeros[ind_tmp] + 1\n",
    "    frequency_vector_1.append(listofzeros)\n",
    "    \n",
    "stop = timeit.default_timer()\n",
    "print(\"kmers Time : \", stop - start) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "a602d40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = []\n",
    "\n",
    "for i in range(len(frequency_vector)):\n",
    "    # Concatenate the two arrays\n",
    "#     combined_data.append(np.concatenate((frequency_vector[i], frequency_vector_1[i])))\n",
    "    combined_data.append(np.concatenate((frequency_vector[i],nanobody_sequences_feat[i], frequency_vector_1[i],antigene_sequences_feat[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "ed7c5a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3481, 35174)"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(combined_data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "57992ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # np.save(\"E:/RA/Pitari/Dataset/rabies_data/Spike2Vec_Rabies_20051_seq_k_3.npy\",frequency_vector)\n",
    "\n",
    "# # np.save(\"E:/RA/T_Cell_Receptor/tcr-bert-main/data/stcrdab/Spike2Vec_PDB_stcrdab_480_seq_k_3.npy\",frequency_vector)\n",
    "# np.save(\"E:/RA/PDB2Vec/Dataset/PDBbind_v2020_other_PL/Spike2Vec_PDB_Bind_3792_seq_k_3.npy\",frequency_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "36dbecb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35174, 744)"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=744)\n",
    "combined_data_pca = pca.fit_transform(combined_data)\n",
    "\n",
    "len(combined_data[0]), len(combined_data_pca[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "f292b55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(combined_data_pca)\n",
    "y = np.array(int_hosts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ec5a18",
   "metadata": {},
   "source": [
    "# Classification Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "83cfc1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_auc_score_multiclass(actual_class, pred_class, average = \"macro\"):\n",
    "\n",
    "    unique_class = set(actual_class)\n",
    "    roc_auc_dict = {}\n",
    "    for per_class in unique_class:\n",
    "        #creating a list of all the classes except the current class \n",
    "        other_class = [x for x in unique_class if x != per_class]\n",
    "\n",
    "        #marking the current class as 1 and all other classes as 0\n",
    "        new_actual_class = [0 if x in other_class else 1 for x in actual_class]\n",
    "        new_pred_class = [0 if x in other_class else 1 for x in pred_class]\n",
    "\n",
    "        #using the sklearn metrics method to calculate the roc_auc_score\n",
    "        roc_auc = roc_auc_score(new_actual_class, new_pred_class, average = average)\n",
    "        roc_auc_dict[per_class] = roc_auc\n",
    "    \n",
    "    \n",
    "    check = pd.DataFrame(roc_auc_dict.items())\n",
    "    return mean(check)\n",
    "\n",
    "def svm_fun_kernel(X_train,y_train,X_test,y_test,kernel_mat):\n",
    "\n",
    "    start = timeit.default_timer()\n",
    "#     stop = timeit.default_timer()\n",
    "#     print(\"NB Time : \", stop - start) \n",
    "#     clf = svm.SVC()\n",
    "    clf = svm.SVC(kernel=kernel_mat)\n",
    "    \n",
    "    #Train the model using the training sets\n",
    "    clf.fit(kernel_mat, y_train)\n",
    "\n",
    "    #Predict the response for test dataset\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    stop = timeit.default_timer()\n",
    "    time_new = stop - start\n",
    "    \n",
    "    svm_acc = metrics.accuracy_score(y_test, y_pred)\n",
    "#     print(\"SVM Accuracy:\",svm_acc)\n",
    "    \n",
    "    svm_prec = metrics.precision_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"SVM Precision:\",svm_prec)\n",
    "    \n",
    "    svm_recall = metrics.recall_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"SVM Recall:\",svm_recall)\n",
    "\n",
    "    svm_f1_weighted = metrics.f1_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"SVM F1 Weighted:\",svm_f1_weighted)\n",
    "    \n",
    "    svm_f1_macro = metrics.f1_score(y_test, y_pred,average='macro')\n",
    "#     print(\"SVM F1 macro:\",svm_f1_macro)\n",
    "    \n",
    "    svm_f1_micro = metrics.f1_score(y_test, y_pred,average='micro')\n",
    "#     print(\"SVM F1 micro:\",svm_f1_micro)\n",
    "    \n",
    "    confuse = confusion_matrix(y_test, y_pred)\n",
    "    #print(\"Confusion Matrix SVM : \\n\", confuse)\n",
    "    #print(\"SVM Kernel Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n",
    "    ######################## Compute ROC curve and ROC area for each class ################\n",
    "    y_prob = y_pred\n",
    "    macro_roc_auc_ovo = roc_auc_score_multiclass(y_test, y_prob, average='macro')\n",
    "#    print(macro_roc_auc_ovo[1])\n",
    "    check = [svm_acc,svm_prec,svm_recall,svm_f1_weighted,svm_f1_macro,macro_roc_auc_ovo[1],time_new]\n",
    "    return(check)\n",
    "    \n",
    "# In[5]\n",
    "##########################  SVM Classifier  ################################\n",
    "def svm_fun(X_train,y_train,X_test,y_test):\n",
    "\n",
    "    #scaler = RobustScaler()\n",
    "    X_train = preprocessing.scale(X_train)  \n",
    "    X_test = preprocessing.scale(X_test)  \n",
    "    \n",
    "    \n",
    "    start = timeit.default_timer()\n",
    "    \n",
    "    \n",
    "    #Create a svm Classifier\n",
    "    clf = svm.SVC(kernel='linear') # Linear Kernel\n",
    "\n",
    "    #Train the model using the training sets\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    #Predict the response for test dataset\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    stop = timeit.default_timer()\n",
    "    time_new = stop - start\n",
    "#     print(\"NB Time : \", stop - start) \n",
    "    \n",
    "    svm_acc = metrics.accuracy_score(y_test, y_pred)\n",
    "#     print(\"SVM Accuracy:\",svm_acc)\n",
    "    \n",
    "    svm_prec = metrics.precision_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"SVM Precision:\",svm_prec)\n",
    "    \n",
    "    svm_recall = metrics.recall_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"SVM Recall:\",svm_recall)\n",
    "\n",
    "    svm_f1_weighted = metrics.f1_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"SVM F1 Weighted:\",svm_f1_weighted)\n",
    "    \n",
    "    svm_f1_macro = metrics.f1_score(y_test, y_pred,average='macro')\n",
    "#     print(\"SVM F1 macro:\",svm_f1_macro)\n",
    "    \n",
    "    svm_f1_micro = metrics.f1_score(y_test, y_pred,average='micro')\n",
    "#     print(\"SVM F1 micro:\",svm_f1_micro)\n",
    "    \n",
    "    confuse = confusion_matrix(y_test, y_pred)\n",
    "    #print(\"Confusion Matrix SVM : \\n\", confuse)\n",
    "    #print(\"SVM Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n",
    "    ######################## Compute ROC curve and ROC area for each class ################\n",
    "    y_prob = y_pred\n",
    "    macro_roc_auc_ovo = roc_auc_score_multiclass(y_test, y_prob, average='macro')\n",
    "#    print(macro_roc_auc_ovo[1])\n",
    "    check = [svm_acc,svm_prec,svm_recall,svm_f1_weighted,svm_f1_macro,macro_roc_auc_ovo[1],time_new]\n",
    "    return(check)\n",
    "    \n",
    "\n",
    "\n",
    "# In[5]\n",
    "##########################  NB Classifier  ################################\n",
    "def gaus_nb_fun(X_train,y_train,X_test,y_test):\n",
    "    start = timeit.default_timer()\n",
    "#     stop = timeit.default_timer()\n",
    "#     print(\"NB Time : \", stop - start) \n",
    "    \n",
    "    \n",
    "    gnb = GaussianNB()\n",
    "    y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "    \n",
    "    stop = timeit.default_timer()\n",
    "    time_new = stop - start\n",
    "\n",
    "\n",
    "    NB_acc = metrics.accuracy_score(y_test, y_pred)\n",
    "#     print(\"Gaussian NB Accuracy:\",NB_acc)\n",
    "\n",
    "    NB_prec = metrics.precision_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Gaussian NB Precision:\",NB_prec)\n",
    "    \n",
    "    NB_recall = metrics.recall_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Gaussian NB Recall:\",NB_recall)\n",
    "    \n",
    "    NB_f1_weighted = metrics.f1_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Gaussian NB F1 weighted:\",NB_f1_weighted)\n",
    "    \n",
    "    NB_f1_macro = metrics.f1_score(y_test, y_pred,average='macro')\n",
    "#     print(\"Gaussian NB F1 macro:\",NB_f1_macro)\n",
    "    \n",
    "    NB_f1_micro = metrics.f1_score(y_test, y_pred,average='micro')\n",
    "#     print(\"Gaussian NB F1 micro:\",NB_f1_micro)\n",
    "    \n",
    "    confuse = confusion_matrix(y_test, y_pred)\n",
    "    #print(\"Confusion Matrix NB : \\n\", confuse)\n",
    "    #print(\"NB Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n",
    "    ######################## Compute ROC curve and ROC area for each class ################\n",
    "    y_prob = y_pred\n",
    "    macro_roc_auc_ovo = roc_auc_score_multiclass(y_test, y_prob, average='macro')\n",
    "    check = [NB_acc,NB_prec,NB_recall,NB_f1_weighted,NB_f1_macro,macro_roc_auc_ovo[1],time_new]\n",
    "    return(check)\n",
    "\n",
    "# In[5]\n",
    "##########################  MLP Classifier  ################################\n",
    "def mlp_fun(X_train,y_train,X_test,y_test):\n",
    "    start = timeit.default_timer()\n",
    "#     stop = timeit.default_timer()\n",
    "#     print(\"NB Time : \", stop - start) \n",
    "    \n",
    "    \n",
    "    # Feature scaling\n",
    "    scaler = StandardScaler()  \n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)  \n",
    "    X_test_2 = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "    # Finally for the MLP- Multilayer Perceptron\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter=1000)  \n",
    "    mlp.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    y_pred = mlp.predict(X_test_2)\n",
    "    \n",
    "    stop = timeit.default_timer()\n",
    "    time_new = stop - start\n",
    "    \n",
    "    MLP_acc = metrics.accuracy_score(y_test, y_pred)\n",
    "#     print(\"MLP Accuracy:\",MLP_acc)\n",
    "    \n",
    "    MLP_prec = metrics.precision_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"MLP Precision:\",MLP_prec)\n",
    "    \n",
    "    MLP_recall = metrics.recall_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"MLP Recall:\",MLP_recall)\n",
    "    \n",
    "    MLP_f1_weighted = metrics.f1_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"MLP F1:\",MLP_f1_weighted)\n",
    "    \n",
    "    MLP_f1_macro = metrics.f1_score(y_test, y_pred,average='macro')\n",
    "#     print(\"MLP F1:\",MLP_f1_macro)\n",
    "    \n",
    "    MLP_f1_micro = metrics.f1_score(y_test, y_pred,average='micro')\n",
    "#     print(\"MLP F1:\",MLP_f1_micro)\n",
    "    \n",
    "    confuse = confusion_matrix(y_test, y_pred)\n",
    "    #print(\"Confusion Matrix MLP : \\n\", confuse)\n",
    "    #print(\"MLP Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n",
    "    ######################## Compute ROC curve and ROC area for each class ################\n",
    "    y_prob = y_pred\n",
    "    macro_roc_auc_ovo = roc_auc_score_multiclass(y_test, y_prob, average='macro')\n",
    "    \n",
    "    check = [MLP_acc,MLP_prec,MLP_recall,MLP_f1_weighted,MLP_f1_macro,macro_roc_auc_ovo[1],time_new]\n",
    "    return(check)\n",
    "\n",
    "# In[5]\n",
    "##########################  knn Classifier  ################################\n",
    "def knn_fun(X_train,y_train,X_test,y_test):\n",
    "    start = timeit.default_timer()\n",
    "#     stop = timeit.default_timer()\n",
    "#     print(\"NB Time : \", stop - start) \n",
    "    \n",
    "    \n",
    "    classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    stop = timeit.default_timer()\n",
    "    time_new = stop - start\n",
    "\n",
    "    knn_acc = metrics.accuracy_score(y_test, y_pred)\n",
    "#     print(\"Knn Accuracy:\",knn_acc)\n",
    "    \n",
    "    knn_prec = metrics.precision_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Knn Precision:\",knn_prec)\n",
    "    \n",
    "    knn_recall = metrics.recall_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Knn Recall:\",knn_recall)\n",
    "    \n",
    "    knn_f1_weighted = metrics.f1_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Knn F1 weighted:\",knn_f1_weighted)\n",
    "    \n",
    "    knn_f1_macro = metrics.f1_score(y_test, y_pred,average='macro')\n",
    "#     print(\"Knn F1 macro:\",knn_f1_macro)\n",
    "    \n",
    "    knn_f1_micro = metrics.f1_score(y_test, y_pred,average='micro')\n",
    "#     print(\"Knn F1 micro:\",knn_f1_micro)\n",
    "    \n",
    "    confuse = confusion_matrix(y_test, y_pred)\n",
    "    #print(\"Confusion Matrix KNN : \\n\", confuse)\n",
    "    #print(\"KNN Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n",
    "    ######################## Compute ROC curve and ROC area for each class ################\n",
    "    y_prob = y_pred\n",
    "    macro_roc_auc_ovo = roc_auc_score_multiclass(y_test, y_prob, average='macro')\n",
    "    \n",
    "    check = [knn_acc,knn_prec,knn_recall,knn_f1_weighted,knn_f1_macro,macro_roc_auc_ovo[1],time_new]\n",
    "    return(check)\n",
    "\n",
    "# In[5]\n",
    "##########################  Random Forest Classifier  ################################\n",
    "def rf_fun(X_train,y_train,X_test,y_test):\n",
    "    start = timeit.default_timer()\n",
    "#     stop = timeit.default_timer()\n",
    "#     print(\"NB Time : \", stop - start) \n",
    "    \n",
    "    \n",
    "    # Import the model we are using\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    # Instantiate model with 1000 decision trees\n",
    "    rf = RandomForestClassifier(n_estimators = 100)\n",
    "    # Train the model on training data\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    \n",
    "    stop = timeit.default_timer()\n",
    "    time_new = stop - start\n",
    "\n",
    "    fr_acc = metrics.accuracy_score(y_test, y_pred)\n",
    "#     print(\"Random Forest Accuracy:\",fr_acc)\n",
    "    \n",
    "    fr_prec = metrics.precision_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Random Forest Precision:\",fr_prec)\n",
    "    \n",
    "    fr_recall = metrics.recall_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Random Forest Recall:\",fr_recall)\n",
    "    \n",
    "    fr_f1_weighted = metrics.f1_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Random Forest F1 weighted:\",fr_f1_weighted)\n",
    "    \n",
    "    fr_f1_macro = metrics.f1_score(y_test, y_pred,average='macro')\n",
    "#     print(\"Random Forest F1 macro:\",fr_f1_macro)\n",
    "    \n",
    "    fr_f1_micro = metrics.f1_score(y_test, y_pred,average='micro')\n",
    "#     print(\"Random Forest F1 micro:\",fr_f1_micro)\n",
    "    \n",
    "    confuse = confusion_matrix(y_test, y_pred)\n",
    "    #print(\"Confusion Matrix RF : \\n\", confuse)\n",
    "    #print(\"RF Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n",
    "    ######################## Compute ROC curve and ROC area for each class ################\n",
    "    y_prob = y_pred\n",
    "    macro_roc_auc_ovo = roc_auc_score_multiclass(y_test, y_prob, average='macro')\n",
    "    \n",
    "    check = [fr_acc,fr_prec,fr_recall,fr_f1_weighted,fr_f1_macro,macro_roc_auc_ovo[1],time_new]\n",
    "    return(check)\n",
    "\n",
    "# In[5]\n",
    "    ##########################  Logistic Regression Classifier  ################################\n",
    "def lr_fun(X_train,y_train,X_test,y_test):\n",
    "    start = timeit.default_timer()\n",
    "#     stop = timeit.default_timer()\n",
    "#     print(\"NB Time : \", stop - start) \n",
    "    \n",
    "\n",
    "    model = LogisticRegression(solver='liblinear', random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    stop = timeit.default_timer()\n",
    "    time_new = stop - start\n",
    "\n",
    "    LR_acc = metrics.accuracy_score(y_test, y_pred)\n",
    "#     print(\"Logistic Regression Accuracy:\",LR_acc)\n",
    "    \n",
    "    LR_prec = metrics.precision_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Logistic Regression Precision:\",LR_prec)\n",
    "    \n",
    "    LR_recall = metrics.recall_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Logistic Regression Recall:\",LR_recall)\n",
    "    \n",
    "    LR_f1_weighted = metrics.f1_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Logistic Regression F1 weighted:\",LR_f1_weighted)\n",
    "    \n",
    "    LR_f1_macro = metrics.f1_score(y_test, y_pred,average='macro')\n",
    "#     print(\"Logistic Regression F1 macro:\",LR_f1_macro)\n",
    "    \n",
    "    LR_f1_micro = metrics.f1_score(y_test, y_pred,average='micro')\n",
    "#     print(\"Logistic Regression F1 micro:\",LR_f1_micro)\n",
    "    \n",
    "    confuse = confusion_matrix(y_test, y_pred)\n",
    "    #print(\"Confusion Matrix LR : \\n\", confuse)\n",
    "    #print(\"LR Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n",
    "    ######################## Compute ROC curve and ROC area for each class ################\n",
    "    y_prob = y_pred\n",
    "    macro_roc_auc_ovo = roc_auc_score_multiclass(y_test, y_prob, average='macro')\n",
    "    \n",
    "    check = [LR_acc,LR_prec,LR_recall,LR_f1_weighted,LR_f1_macro,macro_roc_auc_ovo[1],time_new]\n",
    "    return(check)\n",
    "\n",
    "\n",
    "def fun_decision_tree(X_train,y_train,X_test,y_test):\n",
    "    from sklearn import tree\n",
    "    \n",
    "    start = timeit.default_timer()\n",
    "#     stop = timeit.default_timer()\n",
    "#     print(\"NB Time : \", stop - start) \n",
    "    \n",
    "    clf = tree.DecisionTreeClassifier()    \n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    stop = timeit.default_timer()\n",
    "    time_new = stop - start\n",
    "    \n",
    "    dt_acc = metrics.accuracy_score(y_test, y_pred)\n",
    "#     print(\"Logistic Regression Accuracy:\",LR_acc)\n",
    "    \n",
    "    dt_prec = metrics.precision_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Logistic Regression Precision:\",LR_prec)\n",
    "    \n",
    "    dt_recall = metrics.recall_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Logistic Regression Recall:\",LR_recall)\n",
    "    \n",
    "    dt_f1_weighted = metrics.f1_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Logistic Regression F1 weighted:\",LR_f1_weighted)\n",
    "    \n",
    "    dt_f1_macro = metrics.f1_score(y_test, y_pred,average='macro')\n",
    "#     print(\"Logistic Regression F1 macro:\",LR_f1_macro)\n",
    "    \n",
    "    dt_f1_micro = metrics.f1_score(y_test, y_pred,average='micro')\n",
    "#     print(\"Logistic Regression F1 micro:\",LR_f1_micro)\n",
    "    \n",
    "    confuse = confusion_matrix(y_test, y_pred)\n",
    "    #print(\"Confusion Matrix DT : \\n\", confuse)\n",
    "    #print(\"DT Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n",
    "    ######################## Compute ROC curve and ROC area for each class ################\n",
    "    y_prob = y_pred\n",
    "    macro_roc_auc_ovo = roc_auc_score_multiclass(y_test, y_prob, average='macro')\n",
    "    \n",
    "    check = [dt_acc,dt_prec,dt_recall,dt_f1_weighted,dt_f1_macro,macro_roc_auc_ovo[1],time_new]\n",
    "    return(check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "1824de25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB Time :  0.12405669999861857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Time :  3.5902361999978893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Time :  1.3205674000018917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Time :  4.568386399998417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Time :  1.56319749999966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT Time :  1.4637415000033798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Time :  8.876811699999962\n",
      "NB Time :  0.09629050000148709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Time :  3.212531000001036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Time :  1.2927700000000186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Time :  3.808392399998411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Time :  0.9918168000003789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT Time :  1.3019166999984009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Time :  9.602967200000421\n",
      "NB Time :  0.08070569999836152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Time :  1.6422567999979947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Time :  0.7269727999992028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Time :  3.7809770999992907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Time :  0.9855483999999706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT Time :  1.0407653999973263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Time :  9.388451999999234\n",
      "NB Time :  0.09126330000071903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Time :  1.1740711999991618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Time :  0.7102881999999227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Time :  3.8058668000012403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Time :  0.9548501999997825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT Time :  1.064428300000145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Time :  8.674197500000446\n",
      "NB Time :  0.08397590000095079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Time :  2.0919117999983428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Time :  0.7822094000002835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Time :  3.5491815999994287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Time :  1.469832700000552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT Time :  1.4212427999991633\n",
      "SVM Time :  8.427633100000094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "\n",
    "# print(\"Accuracy   Precision   Recall   F1 (weighted)   F1 (Macro)   F1 (Micro)   ROC AUC\")\n",
    "svm_table = []\n",
    "gauu_nb_table = []\n",
    "mlp_table = []\n",
    "knn_table = []\n",
    "rf_table = []\n",
    "lr_table = []\n",
    "dt_table = []\n",
    "\n",
    "total_splits = 5\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit # or StratifiedShuffleSplit\n",
    "sss = ShuffleSplit(n_splits=total_splits, test_size=0.3)\n",
    "sss.get_n_splits(X, y)\n",
    "\n",
    "for splits_ind in range(total_splits):\n",
    "    train_index, test_index = next(sss.split(X, y)) \n",
    "\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "    start = timeit.default_timer()\n",
    "    gauu_nb_return = gaus_nb_fun(X_train,y_train,X_test,y_test)\n",
    "    stop = timeit.default_timer()\n",
    "    print(\"NB Time : \", stop - start) \n",
    "\n",
    "    start = timeit.default_timer()\n",
    "    mlp_return = mlp_fun(X_train,y_train,X_test,y_test)\n",
    "    stop = timeit.default_timer()\n",
    "    print(\"MLP Time : \", stop - start) \n",
    "\n",
    "    start = timeit.default_timer()\n",
    "    knn_return = knn_fun(X_train,y_train,X_test,y_test)\n",
    "    stop = timeit.default_timer()\n",
    "    print(\"KNN Time : \", stop - start) \n",
    "\n",
    "    start = timeit.default_timer()\n",
    "    rf_return = rf_fun(X_train,y_train,X_test,y_test)\n",
    "    stop = timeit.default_timer()\n",
    "    print(\"RF Time : \", stop - start) \n",
    "\n",
    "    start = timeit.default_timer()\n",
    "    lr_return = lr_fun(X_train,y_train,X_test,y_test)\n",
    "    stop = timeit.default_timer()\n",
    "    print(\"LR Time : \", stop - start) \n",
    "\n",
    "    start = timeit.default_timer()\n",
    "    dt_return = fun_decision_tree(X_train,y_train,X_test,y_test)\n",
    "    stop = timeit.default_timer()\n",
    "    print(\"DT Time : \", stop - start) \n",
    "\n",
    "    start = timeit.default_timer()\n",
    "    svm_return = svm_fun(X_train,y_train,X_test,y_test)\n",
    "    stop = timeit.default_timer()\n",
    "    print(\"SVM Time : \", stop - start) \n",
    "\n",
    "    gauu_nb_table.append(gauu_nb_return)\n",
    "    mlp_table.append(mlp_return)\n",
    "    knn_table.append(knn_return)\n",
    "    rf_table.append(rf_return)\n",
    "    lr_table.append(lr_return)\n",
    "    dt_table.append(dt_return)\n",
    "    svm_table.append(svm_return)\n",
    "\n",
    "    svm_table_final = DataFrame(svm_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                    \"F1 (weighted)\",\"F1 (Macro)\",\"ROC AUC\",\"Runtime\"])\n",
    "    gauu_nb_table_final = DataFrame(gauu_nb_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                    \"F1 (weighted)\",\"F1 (Macro)\",\"ROC AUC\",\"Runtime\"])\n",
    "    mlp_table_final = DataFrame(mlp_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                    \"F1 (weighted)\",\"F1 (Macro)\",\"ROC AUC\",\"Runtime\"])\n",
    "    knn_table_final = DataFrame(knn_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                    \"F1 (weighted)\",\"F1 (Macro)\",\"ROC AUC\",\"Runtime\"])\n",
    "    rf_table_final = DataFrame(rf_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                    \"F1 (weighted)\",\"F1 (Macro)\",\"ROC AUC\",\"Runtime\"])\n",
    "    lr_table_final = DataFrame(lr_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                    \"F1 (weighted)\",\"F1 (Macro)\",\"ROC AUC\",\"Runtime\"])\n",
    "\n",
    "    dt_table_final = DataFrame(dt_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                    \"F1 (weighted)\",\"F1 (Macro)\",\"ROC AUC\",\"Runtime\"])\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "7c7c793c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 (weighted)</th>\n",
       "      <th>F1 (Macro)</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>Runtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.791196</td>\n",
       "      <td>0.795693</td>\n",
       "      <td>0.791196</td>\n",
       "      <td>0.790190</td>\n",
       "      <td>0.789777</td>\n",
       "      <td>0.790140</td>\n",
       "      <td>8.803923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NB</th>\n",
       "      <td>0.695311</td>\n",
       "      <td>0.736747</td>\n",
       "      <td>0.695311</td>\n",
       "      <td>0.679537</td>\n",
       "      <td>0.678009</td>\n",
       "      <td>0.691415</td>\n",
       "      <td>0.085273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.811292</td>\n",
       "      <td>0.813778</td>\n",
       "      <td>0.811292</td>\n",
       "      <td>0.810844</td>\n",
       "      <td>0.810592</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>2.326290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.844211</td>\n",
       "      <td>0.845081</td>\n",
       "      <td>0.844211</td>\n",
       "      <td>0.844167</td>\n",
       "      <td>0.844028</td>\n",
       "      <td>0.844266</td>\n",
       "      <td>0.952556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.896651</td>\n",
       "      <td>0.903483</td>\n",
       "      <td>0.896651</td>\n",
       "      <td>0.896331</td>\n",
       "      <td>0.896327</td>\n",
       "      <td>0.897669</td>\n",
       "      <td>3.889807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.826603</td>\n",
       "      <td>0.826935</td>\n",
       "      <td>0.826603</td>\n",
       "      <td>0.826620</td>\n",
       "      <td>0.826468</td>\n",
       "      <td>0.826672</td>\n",
       "      <td>1.182620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>0.847081</td>\n",
       "      <td>0.847517</td>\n",
       "      <td>0.847081</td>\n",
       "      <td>0.847039</td>\n",
       "      <td>0.846859</td>\n",
       "      <td>0.846888</td>\n",
       "      <td>1.246398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Accuracy  Precision    Recall  F1 (weighted)  F1 (Macro)   ROC AUC  \\\n",
       "SVM  0.791196   0.795693  0.791196       0.790190    0.789777  0.790140   \n",
       "NB   0.695311   0.736747  0.695311       0.679537    0.678009  0.691415   \n",
       "MLP  0.811292   0.813778  0.811292       0.810844    0.810592  0.810811   \n",
       "KNN  0.844211   0.845081  0.844211       0.844167    0.844028  0.844266   \n",
       "RF   0.896651   0.903483  0.896651       0.896331    0.896327  0.897669   \n",
       "LR   0.826603   0.826935  0.826603       0.826620    0.826468  0.826672   \n",
       "DT   0.847081   0.847517  0.847081       0.847039    0.846859  0.846888   \n",
       "\n",
       "      Runtime  \n",
       "SVM  8.803923  \n",
       "NB   0.085273  \n",
       "MLP  2.326290  \n",
       "KNN  0.952556  \n",
       "RF   3.889807  \n",
       "LR   1.182620  \n",
       "DT   1.246398  "
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#taking average of all k-fold performance values\n",
    "final_mean_mat = []\n",
    "\n",
    "final_mean_mat.append(np.transpose((list(svm_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(gauu_nb_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(mlp_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(knn_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(rf_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(lr_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(dt_table_final.mean()))))\n",
    "\n",
    "final_avg_mat = DataFrame(final_mean_mat,columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"ROC AUC\",\"Runtime\"], \n",
    "                          index=[\"SVM\",\"NB\",\"MLP\",\"KNN\",\"RF\",\"LR\",\"DT\"])\n",
    "\n",
    "final_avg_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "1a258426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 (weighted)</th>\n",
       "      <th>F1 (Macro)</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>Runtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.006253</td>\n",
       "      <td>0.008920</td>\n",
       "      <td>0.006253</td>\n",
       "      <td>0.005819</td>\n",
       "      <td>0.005977</td>\n",
       "      <td>0.006391</td>\n",
       "      <td>0.506730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NB</th>\n",
       "      <td>0.004364</td>\n",
       "      <td>0.008055</td>\n",
       "      <td>0.004364</td>\n",
       "      <td>0.007038</td>\n",
       "      <td>0.007950</td>\n",
       "      <td>0.007683</td>\n",
       "      <td>0.014431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.019334</td>\n",
       "      <td>0.018529</td>\n",
       "      <td>0.019334</td>\n",
       "      <td>0.019405</td>\n",
       "      <td>0.019243</td>\n",
       "      <td>0.018814</td>\n",
       "      <td>1.025585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.015302</td>\n",
       "      <td>0.015304</td>\n",
       "      <td>0.015302</td>\n",
       "      <td>0.015211</td>\n",
       "      <td>0.015209</td>\n",
       "      <td>0.014869</td>\n",
       "      <td>0.308848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.011895</td>\n",
       "      <td>0.010014</td>\n",
       "      <td>0.011895</td>\n",
       "      <td>0.012021</td>\n",
       "      <td>0.012072</td>\n",
       "      <td>0.011881</td>\n",
       "      <td>0.388460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.011551</td>\n",
       "      <td>0.011383</td>\n",
       "      <td>0.011551</td>\n",
       "      <td>0.011518</td>\n",
       "      <td>0.011588</td>\n",
       "      <td>0.011409</td>\n",
       "      <td>0.296897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>0.013624</td>\n",
       "      <td>0.013728</td>\n",
       "      <td>0.013624</td>\n",
       "      <td>0.013547</td>\n",
       "      <td>0.013629</td>\n",
       "      <td>0.013385</td>\n",
       "      <td>0.195328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Accuracy  Precision    Recall  F1 (weighted)  F1 (Macro)   ROC AUC  \\\n",
       "SVM  0.006253   0.008920  0.006253       0.005819    0.005977  0.006391   \n",
       "NB   0.004364   0.008055  0.004364       0.007038    0.007950  0.007683   \n",
       "MLP  0.019334   0.018529  0.019334       0.019405    0.019243  0.018814   \n",
       "KNN  0.015302   0.015304  0.015302       0.015211    0.015209  0.014869   \n",
       "RF   0.011895   0.010014  0.011895       0.012021    0.012072  0.011881   \n",
       "LR   0.011551   0.011383  0.011551       0.011518    0.011588  0.011409   \n",
       "DT   0.013624   0.013728  0.013624       0.013547    0.013629  0.013385   \n",
       "\n",
       "      Runtime  \n",
       "SVM  0.506730  \n",
       "NB   0.014431  \n",
       "MLP  1.025585  \n",
       "KNN  0.308848  \n",
       "RF   0.388460  \n",
       "LR   0.296897  \n",
       "DT   0.195328  "
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#taking average of all k-fold performance values\n",
    "final_mean_mat = []\n",
    "\n",
    "final_mean_mat.append(np.transpose((list(svm_table_final.std()))))\n",
    "final_mean_mat.append(np.transpose((list(gauu_nb_table_final.std()))))\n",
    "final_mean_mat.append(np.transpose((list(mlp_table_final.std()))))\n",
    "final_mean_mat.append(np.transpose((list(knn_table_final.std()))))\n",
    "final_mean_mat.append(np.transpose((list(rf_table_final.std()))))\n",
    "final_mean_mat.append(np.transpose((list(lr_table_final.std()))))\n",
    "final_mean_mat.append(np.transpose((list(dt_table_final.std()))))\n",
    "\n",
    "final_avg_mat = DataFrame(final_mean_mat,columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"ROC AUC\",\"Runtime\"], \n",
    "                          index=[\"SVM\",\"NB\",\"MLP\",\"KNN\",\"RF\",\"LR\",\"DT\"])\n",
    "\n",
    "final_avg_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971dcdab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92613df1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
